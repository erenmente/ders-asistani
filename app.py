from flask import Flask, render_template, request, jsonify
import google.generativeai as genai
import os
import time
from dotenv import load_dotenv

# 1. AYARLARI YÃœKLE
load_dotenv()
app = Flask(__name__)

API_KEY = os.getenv("GEMINI_API_KEY")

if not API_KEY:
    print("âŒ HATA: API AnahtarÄ± bulunamadÄ±!")
else:
    genai.configure(api_key=API_KEY)

# --- SÄ°STEM TALÄ°MATLARI ---
ALGO_PROMPT = """
ROL: FÄ±rat Ãœniversitesi YazÄ±lÄ±m MÃ¼h. Algoritma MentorÃ¼ (Java UzmanÄ±).
GÃ–REV: Asla direkt kod verme. Ã–nce mantÄ±ÄŸÄ± anlat. Clean Code kullan.
"""

BBG_PROMPT = """
ROL: Bilgisayar Bilimleri Akademisyeni.
GÃ–REV: KonularÄ± mÃ¼hendislik formasyonuyla, derinlemesine ve analojilerle anlat.
"""

# --- MODEL LÄ°STESÄ° (STRATEJÄ°K SIRALAMA) ---
# 1. 'gemini-flash-latest': En gÃ¼venli liman. Google senin iÃ§in en boÅŸ sunucuyu seÃ§er.
# 2. 'gemini-2.0-flash': Standart sÃ¼rÃ¼m.
# 3. 'gemini-2.0-flash-lite-preview...': Az Ã¶nce kullandÄ±ÄŸÄ±mÄ±z (Yedek)
MODEL_LIST = [
    'gemini-flash-latest',       # <-- JOKER (En YÃ¼ksek Ã–ncelik)
    'gemini-2.0-flash',          # <-- Standart
    'gemini-2.0-flash-exp',      # <-- HÄ±zlÄ±
    'gemini-2.0-flash-lite-preview-02-05' 
]

active_models = {}

def get_working_chat_session(mode):
    """SÄ±rayla modelleri dener, Ã§alÄ±ÅŸan ilkini dÃ¶ndÃ¼rÃ¼r."""
    global active_models
    
    if mode in active_models:
        return active_models[mode]

    print(f"ğŸ•µï¸â€â™‚ï¸ '{mode}' iÃ§in en uygun model aranÄ±yor...")
    
    for model_name in MODEL_LIST:
        try:
            print(f"ğŸ‘‰ Deneniyor: {model_name}...")
            instruction = ALGO_PROMPT if mode == 'algo' else BBG_PROMPT
            model = genai.GenerativeModel(model_name, system_instruction=instruction)
            
            # Test atÄ±ÅŸÄ±
            chat = model.start_chat(history=[])
            
            active_models[mode] = chat
            print(f"âœ… BAÅARILI! '{model_name}' devreye alÄ±ndÄ±.")
            return chat
            
        except Exception as e:
            print(f"âŒ {model_name} pas geÃ§ildi: {e}")
            continue

    raise Exception("TÃ¼m modeller meÅŸgul veya kotasÄ± dolu.")

# --- ROTALAR ---

@app.route('/')
def home():
    return render_template('index.html')

@app.route('/sor', methods=['POST'])
def sor():
    try:
        data = request.json
        user_input = data.get('message')
        mode = data.get('mode') 

        if not user_input:
            return jsonify({'response': "BoÅŸ mesaj."})

        # --- RETRY (TEKRAR DENEME) MEKANÄ°ZMASI ---
        # Hata alÄ±rsak 5 saniye bekleyip tekrar deniyoruz (Toplam 3 hak)
        max_retries = 3
        
        for i in range(max_retries):
            try:
                # 1. Aktif sohbeti al (veya yenisini bul)
                active_chat = get_working_chat_session(mode)
                
                # 2. MesajÄ± gÃ¶nder
                response = active_chat.send_message(user_input)
                return jsonify({'response': response.text})

            except Exception as e:
                error_msg = str(e)
                print(f"âš ï¸ Deneme {i+1}/{max_retries} BaÅŸarÄ±sÄ±z: {error_msg}")
                
                # Model hatasÄ± varsa hafÄ±zadan sil ki bir sonraki turda yenisini seÃ§sin
                if mode in active_models:
                    del active_models[mode]
                
                # Son hak deÄŸilse bekle
                if i < max_retries - 1:
                    time.sleep(4) # Bekleme sÃ¼resini 4 saniyeye Ã§Ä±kardÄ±m
                else:
                    return jsonify({'response': "âš ï¸ Sunucular ÅŸu an aÅŸÄ±rÄ± yoÄŸun. LÃ¼tfen 30 saniye bekleyip tekrar dene."})

    except Exception as e:
        return jsonify({'response': f"Sistem hatasÄ±: {str(e)}"})

@app.route('/temizle', methods=['POST'])
def temizle():
    global active_models
    active_models = {}
    return jsonify({'status': 'ok'})

if __name__ == '__main__':
    app.run(debug=True)